{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import sys\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()\n",
    "driver.get(\"https://hanchi.ihp.sinica.edu.tw/mqlc/hanjishilu?7:798791797:10:/raid/ihp_ebook2/hanji/ttsweb.ini:::@SPAWN#top\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_books_tree_graph():\n",
    "    msl_btn = driver.find_element(By.XPATH, '//*[@id=\"frmTitle\"]/table/tbody/tr[4]/td/div/table/tbody/tr[3]/td[4]/a[2]')\n",
    "    msl_btn.click()\n",
    "    \n",
    "    next_chapter_btn = driver.find_element(By.XPATH, '/html/body/form/table/tbody/tr[2]/td[3]/table/tbody/tr[1]/td[2]/a[1]')\n",
    "    next_chapter_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_books_tree_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['版本說明', '校印本明實錄總目', '校印明實錄序', '校勘記凡例', '太祖', '太宗', '仁宗', '宣宗', '英宗', '憲宗', '孝宗', '武宗', '世宗', '穆宗', '神宗', '光宗', '熹宗', '附錄']\n"
     ]
    }
   ],
   "source": [
    "books_list_cur = driver.find_element(By.CLASS_NAME, 'treehit')\n",
    "books_list = driver.find_elements(By.CLASS_NAME, 'tree')\n",
    "require_book_list = [ book.text for book in books_list if book.text != '史' and book.text != '編年' and book.text != '明實錄' and book.text != '校勘記' ]\n",
    "all_books_list = list()\n",
    "all_books_list.append(books_list_cur.text)\n",
    "all_books_list += require_book_list\n",
    "\n",
    "print(all_books_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_cleaning(origin_title):\n",
    "    clean_title = re.sub(u'\\u3000', ' ', origin_title).strip()\n",
    "    clean_title = re.sub(r'\\(.+?\\)|\\d+日', '', clean_title).strip()\n",
    "    title_list = [item for item in clean_title.split('／')[2:] if item != '']\n",
    "    title = ' '.join(title_list)\n",
    "\n",
    "    return title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_size_mb(d):\n",
    "    return sys.getsizeof(d) / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataframe(dict_data):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for key, value in dict_data.items():\n",
    "        new_df = pd.DataFrame({'field': [value['field']] * len(value['text']), 'title': key, 'text': value['text']})\n",
    "        df = pd.concat([df, new_df], ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_to_current_dir(search_text):\n",
    "    main_page_btn = driver.find_element(By.XPATH, \"/html/body/form/table/tbody/tr[1]/td/table/tbody/tr[1]/td/table/tbody/tr/td[1]/a\")\n",
    "    main_page_btn.click()\n",
    "    database_btn = driver.find_element(By.XPATH, \"/html/body/table/tbody/tr/td/a\")\n",
    "    database_btn.click()\n",
    "    load_books_tree_graph()\n",
    "\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"frmTitle\"]/table/tbody/tr[2]/td/table/tbody/tr[1]/td/input[2]').clear()\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"frmTitle\"]/table/tbody/tr[2]/td/table/tbody/tr[1]/td/input[2]').send_keys(search_text)\n",
    "    search_btn = driver.find_element(By.XPATH, '//*[@id=\"frmTitle\"]/table/tbody/tr[2]/td/table/tbody/tr[6]/td/input[1]')\n",
    "    search_btn.click()\n",
    "    to_book_btn = driver.find_element(By.XPATH, '/html/body/form/table/tbody/tr[2]/td[3]/div/table[2]/tbody/tr[2]/td[4]/a')\n",
    "    to_book_btn.click()\n",
    "    to_pre_target_page = driver.find_element(By.XPATH, \"/html/body/form/table/tbody/tr[2]/td[3]/table[2]/tbody/tr[1]/td[2]/a\")\n",
    "    to_pre_target_page.click()\n",
    "    to_target_page_btn = driver.find_element(By.XPATH, \"/html/body/form/table/tbody/tr[2]/td[3]/table/tbody/tr[1]/td[2]/a[2]\")\n",
    "    to_target_page_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait = WebDriverWait(driver, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     16\u001b[0m book_title \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCLASS_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgobookmark\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m title \u001b[38;5;241m=\u001b[39m title_cleaning(\u001b[43mbook_title\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_books_list[book_counter] \u001b[38;5;129;01min\u001b[39;00m title:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m title \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m msl_corpus:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "msl_corpus = dict()\n",
    "field_num = 0\n",
    "book_counter = 0\n",
    "size_limit = 1\n",
    "file_counter = 1\n",
    "\n",
    "while 1:\n",
    "    try:\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        if book_counter > 17:\n",
    "            print(f\"book_counter: {book_counter}\")\n",
    "            break\n",
    "        \n",
    "        book_title = driver.find_element(By.CLASS_NAME, 'gobookmark')\n",
    "        title = title_cleaning(book_title.text)\n",
    "\n",
    "        if all_books_list[book_counter] in title:\n",
    "            if title not in msl_corpus:\n",
    "                field_num += 1\n",
    "                msl_corpus[title] = {\n",
    "                    \"field\": field_num,\n",
    "                    \"text\": []\n",
    "                }\n",
    "        \n",
    "            div_text = soup.select_one('div.div2').text.strip()\n",
    "            div_texts = soup.select('div.div2 div')\n",
    "            for div in div_texts:\n",
    "                msl_corpus[title][\"text\"].append(div.text.strip())\n",
    "\n",
    "            next_page_btn = driver.find_element(By.XPATH, '//img[@title=\"下一章\"]')\n",
    "            next_page_btn.click()\n",
    "        else:\n",
    "            book_counter += 1\n",
    "        \n",
    "        if dict_size_mb(msl_corpus) >= size_limit:\n",
    "            print(f\"size: {dict_size_mb(msl_corpus)}\")\n",
    "            df = to_dataframe(msl_corpus)\n",
    "            df.to_csv(f'./origin_craw_data/msl_corpus_part{file_counter}.csv', index=False)\n",
    "            print(f'Data part {file_counter} written to CSV.')\n",
    "\n",
    "            msl_corpus.clear()\n",
    "            file_counter += 1\n",
    "\n",
    "    except NoSuchElementException as e:\n",
    "        reload_to_current_dir(msl_corpus[title]['text'][-1][:15])\n",
    "        print(\"No such element exception.\")\n",
    "\n",
    "    except TimeoutException:\n",
    "        driver.refresh()\n",
    "\n",
    "if msl_corpus:\n",
    "    df = to_dataframe(msl_corpus)\n",
    "    df.to_csv(f'./origin_craw_data/msl_corpus_part{file_counter}.csv', index=False)\n",
    "    print(f'Final part {file_counter} written to CSV.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'○夜太陰入軒轅'\n"
     ]
    }
   ],
   "source": [
    "pp(msl_corpus['明實錄 太祖 卷二百二十七 洪武二十六年四月至五月 四月'][\"text\"][11][:15])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pv10_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
